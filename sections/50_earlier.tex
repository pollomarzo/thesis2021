% !TEX root = ../main.tex

\documentclass[../main.tex]{subfiles}
\graphicspath{{\subfix{../img/}}}

\begin{document}

Although the official birth of the ``Cognitive Science" institutions is in the late 1970s, reasoning about thought has been a staple in philosophical research for centuries. Because of the scope of this document, we will focus on a few important concepts, and use them to set the stage for the first large shift of ideas.

\subsubsection{Mathematics and Computer Science}
Some of the most relevant contributions to the ``reasoning as computation" line of research come from Mathematics and what would later become Theoretical Computer Science. We will outline some of them here, while we trace part of the history of conceiving of thought as computation, first, and computers as devices for computation, second. In this respect, the following step is to be expected: can we use devices for the computation that thoughts ``work" with?


\vspace{4pt}
\textbf{Boole's Laws of Thought and Boolean Algebra.}\sidekeyword{Laws of thought modeled in mathematics, using algebra}
To avoid going too deep in mathematical concepts for our purposes, we can think of Boolean algebra as the branch of algebra where the variables can be either true or false (1 and 0), and the main operations on its variables are conjuction (and, $\wedge$), disjunction (or, $\vee$), negation (not, $\neg$). Through these, logical operations can be described.
In "An Investigation of the Laws of Thought on Which are Founded the Mathematical Theories of Logic and Probabilities", one of the author's two monographs on algebraic logic, George Boole, then mathematics professor in Ireland, introduces Boole's algebra as an extension to Aristotle's logic. In it, Boole provides Aristotle's algebra with mathematical foundations, and expands it from two-term to any-term. Boole's algebra differs from modern Boolean algebra (in Boole's algebra \textit{uninterpretable} terms exist) and cannot be inteprepted as set operations; still, its introduction marked a step towards the formalization of laws of thought and a possible bridge between mathematical research and thinking processes (even the title of the book it was introduced in gives a very clear direction). Boolean algebra would instead be developed by Boole's successors (Jevons, Peirce, Schroder and Huntington in particular); this work allows boolean algebra to now be defined by the Stanford Encyclopedia as
\begin{quote}
    the algebra of two-valued logic with only sentential connectives, or equivalently of algebras of sets under union and complementation.
\end{quote}


\vspace{4pt}
\textbf{Automata theory.}\sidekeyword{Modeling algebra, so thought, is possible through some computational structure}
The study of how automatic calculators (more properly, abstract machines or automata) can be used to compute and solve problems is a part of theoretical computer science research. The history of Automata Theory is especially interesting, as it will let us meet some important researchers: it features two neurophysiologists, Warren McCulloch and Walter Pitts, and is thus born from the desire of modeling human thought itself. The first model was proposed in 1943 \cite{mccullochLogicalCalculusIdeas1943}, in a seminal paper that also introduced other research themes we will come back to later. A little over twelve years later, two computer scientists, Mealy and Moore, generalized the theory to more powerful machines, ``finite-state machines". The general idea behind them is this: starting from an input and a set of states, a \textit{transition function} maps the current state and an input to an output together with the next state. They do not have any memory, and as such can only ``solve" simpler problems: if used to recognize languages, they can only recognize regular ones.

More powerful abstract machines had already been proposed: Turing had introduced ``Turing machines" in 1937 \cite{turingComputableNumbersApplication1937}, as part of his proof of the Entscheidungsproblem. \sout{The relationship between automata ``expressive power" and language complexity will be explained in later chapters.} \todo{undecidability problem already puts a stop to modeling thought as maths?}

\vspace{4pt}
\textbf{Cybernetics.}\sidekeyword{Study of feedback is subject-agnostic, self replication, artificial neural networks}
Although in recent years the term ``cybernetic" has been used to mean futuristic/sci-fi technology, Cybernetics is a transdisciplinary discipline that studies regulatory systems. The core of the discipline are feedback loops (or circular causality), where the result of action is taken as input for (choosing) future actions. Cybernetics isn't bound to any particular usage, so its applications include biology, sociology, computer science, robotics and many others. Its flexible approach led to many different definitions: two early ones are the one used in Macy cybernetics conferences, ``the study of circular causal and feedback mechanisms in biological and social systems"\cite{steerCyberneticsCircularCausal1952}, and the definition by Norbert Wiener, considered the originator of cybernetics, ``the scientific study of control and communication in the animal and the machine"\cite{wienerCyberneticsControlCommunication1961}. Although the word itself was used by Plato to signify the governance of people, our interest resides in contemporary cybernetics, born in the 1940s. Before the aforementioned paper by McCulloch and Pitts, the study of feedback was considered by Anokhin in 1935 \cite{anokhinProblemsCentrePeriphery1935} (physiologist). In the same year as the McCulloch-Pitts paper was published, Wiener, together with Rosenblueth and Bigelow, published ``Behavior, Purpose and Teleology" \cite{rosenbluethBehaviorPurposeTeleology1943}: these three researchers, together with McCulloch, Turing, Grey Walter and Ross Ashby, would go on to establish the discipline of cybernetics. Wiener coined the term to denote ``teleological mechanisms".

An important addition to the field would be the Von Neumann cellular automata: these are another model of computation part of automata theory. A cellular automata is a grid of cells (of any dimensions, but for clarity, consider a 2-dimensional one first), where each cell has a finite number of states it can be in; the cellular automata evolves by moving from generation zero ($t=0$) to the next generation ($t=1$) following mathematical rules: the state of every cell is determined by its past state and the surrounding cells. Without going into the specific rules Von Neumann determined, this is relevant to us because it introduces two fundamental concepts: self replication, soon to be adopted by cybernetics as a core concept, and the formal study of evolutionary mechanisms in simulation. Another fundamental contribution from cybernetics is the creation of Artificial Neural Networks, introduced in the same McCulloch-Pitts paper we mentioned earlier.


\vspace{4pt}
\textbf{Information theory and technical advances.}
As we have seen, theoretical advances were many and varied, but the technical advances were what drove the ability to put those in practice. Among those, we have to mention the move from electromechanical devices to vacuum tube-based computers, which gave birth to a device for controlling the connections between telephone exchanges, thanks to Flowers, in 1934. The record for the first general-purpose stored-program (as in, controlled by wires, the opposite of a stored-program computer) went to Konrad Zuse, with the Z3 machine. This machine also used a binary system, but it was not a universal computer. In 1944, the Bletchley Park cryptanalysts started using Colossus. The first Turing-complete (i.e. with the same computing ability as the Turing machine) computer was completed in 1945. It used over 18.000 vacuum tubes. The first stored-program computer, built as a testbed for new technology and design, was the Manchester Baby, ran in June 1948\cite{ComputerResurrectionIssue2012}.

As part of the advances of this period, we must mention the birth and development of Information Theory. Information Theory encompasses the study of quantification, storage and communication of information, in digital form. After being introduced by Nyquist and Ralph \cite{nyquistCertainTopicsTelegraph1928}, the field was firmly established by Shannon's ``A Mathematical Theory of Communication" in 1948. Without going into details, its main influences include the bit as a unit of informationa and the necessity of redundancy of a source when using unreliable communication channels.

Lastly, we note that neuroscience had new tools at his disposal: electrophysiological techniques, such as brain stimulation, single cell recording and EEG recording \cite{InternationalEncyclopediaSocial} were instrumental to the research into localization studies (such as deficits derived from brain lesions) approached by Geschwind in the 1950s.

\subsubsection{DCS}
The DCS landscape around 1950 was strongly rooted in Behaviorism, with hints of the revolution that was soon to come. Some of the larger influences from the Computer Science side, such as the McCullough Pitts artificial neural network we mentioned, would in fact have a relatively small impact and be re-discovered later.

\vspace{4pt}
\textbf{Behaviorism.}\sidekeyword{Psychology as a science}
Behaviorism emerged as the dominant school in Western psychology as a reaction to depth psychology and other forms of psychology that did not fit well with scientific experimental verification. That is not to say it was unprecedented: Thorndike presented the law of effect (using consequences to strengthen or weaken behaviour) in 1898. Still, behaviorism was introduced as ``methodological behaviorism" by a 1924 publication by John Watson \cite{watsonUnverbalizedHumanBehavior1924}, and then further expanded by many researchers, of which we must mention B. F. Skinner.

Behaviorism, more than a way to impose empirical constraints on studying psychology, is a doctrine of how to do behavioral science itself. The Stanford Encyclopedia identifies three claims as the roots of behaviorism (as a doctrine):
\begin{itemize}
    \item Psychology is the science of behavior. Psychology is not the science of the inner mind – as something other or different from behavior.
    \item Behavior can be described and explained without making ultimate reference to mental events or to internal psychological processes. The sources of behavior are external (in the environment), not internal (in the mind, in the head).
    \item In the course of theory development in psychology, if, somehow, mental terms or concepts are deployed in describing or explaining behavior, then either (a) these terms or concepts should be eliminated and replaced by behavioral terms or (b) they can and should be translated or paraphrased into behavioral concepts.
\end{itemize}
These fundamental truths identify three of the various flavours behaviorism is studied in. Skinner, mentioned above, was the first to suggest that covert behavior, such as cognition and emotions, is governed by the same controlling variables as observable behavior: although focused on the third ``truth", his philosophy combines all three mentioned pillars, and is described as \textit{radical behaviorism} by skinner himself \cite{skinnerBehaviorism1974}.

One can easily see how the philosophy itself forced the practitioners into a state of absolute experimental dependency, which constrained the concept explored to the scientific realm. At the same time, its complete rejection of mental processes (or at least their relevance to scientific study) is the complete opposite of the assumptions that were made on the "CS" side of comprehension. Other behaviorists, though, were less radical: Clark Hull was willing to put drive inbetween stimulus and response, but only to create a corresponding theory that explained it in terms of behavior\cite{hullGoalAttractionDirecting1931}; Edward Tolman, instead, proposed rats navigate a maze following a mental map\cite{tolmanCognitiveMapsRats1948}.

\vspace{4pt}
\textbf{Cognitive signs.}\sidekeyword{Psychophysical isomorphism}
Just like Tolman, other cognitive-leaning psychologists proposed ideas that did not fit with the behavioral narrative. Among them, we mention some relevant ones. The Gestalt psychology refused the behavioristic assumption that conscious experience could be considered by reducing it to the sum of it parts, and proposed the principle of totality; it also proposed the principle of psychophysical isomorphism, which meant the cerebral activity was correlated to conscious activity \cite{wagemansCenturyGestaltPsychology2012}. Vygotsky and Luria pioneered ``cultural-historical psychology", which noted the role of culture and language in the development of higher pschological functions; Luria, alone, also published research on individuals' thought processes as his doctoral dissertation.

Lastly, we mention Miller, who was just a trainee at Stevens's Psychoacoustic Laboratory at Harvard: he will soon become relevant, as part of the 1956 cognitive revolution.

\vspace{4pt}
In our exploration of the state of disciplines around 1950, it is clear that Computer Science was firmly en route to a first attempt at thought modeling though mathematical "symbols": if, as they suspected, thought was to be considered a use of (or better yet, possible to model with) algebra, then once physical computers were capable enough they would be capable of thought. On the other side of the fence, DCS was still firmly rooted in behaviorism: in their view, the entire discussion would be based on false premises which were in turn based on wrongful research; the roots of human behavior were to be found in human behavior itself, and assuming otherwise was not only useless but unscientific, as it would lead to unprovable theories and impossible experiments. At the same time, cognitive suggestions were starting to appear, challenging the general (or at the very least American) current view.


\end{document}
