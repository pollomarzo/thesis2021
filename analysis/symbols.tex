% !TEX root = ../main.tex

\documentclass[../main.tex]{subfiles}
\begin{document}

\section{Symbols, Subsymbols and their Integration}

In this section, we will analyze the differences between symbolic and connectionist approaches, and investigate what the possible avenues for integration are. This subject is being heavily researched, and the community's interest in it has increased massively in the last few years; still, since we will need some cross-historical notions, we decided to include it as a separate section instead of the final section of the History chapter.

\subsection{Semantic differences}
Throughout the History chapter, we did not give a strict, overarching definition of the two: at the same time, we explored researchers' opinions, from Boole's modeling of thought and the Physical System Hypothesis to the uninterpretability of Neural Networks, which gives you a clear picture of the two sides of the spectrum. For the sake of clarity, we report a section from \cite{smolenskyConnectionistAISymbolic1987}:
\begin{quote}
    [...] goals, beliefs, knowledge, and so on are all formalized as symbolic structures. [...] Thus, in a medical expert system, we expect to find structures like (IF FEVER THEN (HYPOTHESIZE INFECTION)). These symbolic structures are operated on by symbol manipulation procedures composed of primitive operations like concatenating lists, and extracting elements from lists. According to the symbolic paradigm, it is in terms of such operations that we are to understand cognitive processes. [...] The symbolic level that implements knowledge structures is alleged to be exact and complete. That means that lower levels are unnecessary for accurately describing cognition in terms of the semantically interpretable elements.
\end{quote}

He then goes on to note that this paradigm, called by Hofstadter the `Boolean dream', has (at least by itself) proven to give little insight into how the brain works, and tends to build brittle, rigid systems.

The largest difference between the two, he notes, is then the semantic interpretation of the formal models: while in symbolic systems symbols are used to denote the concepts themselves, semantically interpretable, in connectionist models the semantically interpreted entities are \textit{patterns of activation}. This leaves us with a spectrum of possible representation paradigms; the two ends are fully local or localized representations (symbolic) and fully distributed representations (connectionist). The means by which these distributed representations are handled cannot be the symbol manipulation procedures, but are instead differential equations on the dynamical system implemented by the network, which uses continuous variable as opposed to discrete ones.

\subsection{Neuro-symbolic approaches}
Clearly, the brain works with networks of biological neurons propagating activation and strengthening and weakening connections. At the same time, symbolic-driven thought \textit{is} possible, as humans are able to conduct symbol manipulation procedures on concepts. This means that somehow, somewhere the two are integrated one way or another. Although, for length reasons, we were unable to give proper discussion to Neural Networks issues, their uninterpretability (because of distributed representations of both symbols \textit{and} the rules governing them, \enquote*{if you open them up and peer inside,  all you can see is a big  pile of goo} \cite{mozerUsingRelevanceReduce1989}) and vulnerability to adversarial attacks (i.e. manufactured examples trick networks) has been leading practitioners to the same conclusion as researchers: it would be beneficial to attempt hybrid systems, with both paradigm's advantages and none of the issues.

To classify hybrid approaches, we will follow Henry Kaytz's taxonomy, presented at AAAI 2020\cite{kautzAAAI2020TalkSlides2020}: he distinguishes four types of integration:
\begin{enumerate}
    \item \textbf{Type 1.} The first type is deep learning itself, i.e. considering symbolic manipulation as an emergent behavior, when symbols constitute input (text, questions, images) and output (text, categories).
    \item \textbf{Type 2.} The second type are hybrid systems like DeepMind's AlphaGo, where a neural network is coupled with a symbolic problem solver (in this case, Monte Carlo tree search).
    \item \textbf{Type 3.} The third type is a hybrid system where a NN solves one task, then interacts with a symbolic system specialised in a complementary task. An example is NS-VQA\cite{yiNeuralsymbolicVQADisentangling2018}, where NN tackle vision and language while reasoning is left for a symbolic system.
    \item \textbf{Type 4.} This type includes those systems in which symbolic knowledge is compiled into the training set, with \cite{lampleDeepLearningSymbolic2019} brought as an example.
    \item \textbf{Type 5.} Type 5 networks are the tightly-coupled, distributed neural-symbolic systems, with symbolic logic rules used as templates for structures in the neural network. Examples include Tensor Product Representations\cite{mccoyRNNsImplicitlyImplement2019} and Logic Tensor Networks\cite{serafiniLogicTensorNetworks2016}.
    \item \textbf{Type 6.} Finally, Type 6 systems would be able to complete symbolic reasoning inside a neural engine, and enable combinatorial reasoning. He notes the objective of such an architecture would be expert reasoning, instead of commonsense reasoning, and writes \enquote*{a step toward superintelligence, not human intelligence}.
\end{enumerate}

This concludes how far we're going to go with our exploration into hybrid systems. We wish to conclude by noting that, although interest is high, research into them is still in its infancy: as a counterpoint to hybrid systems' effectiveness, we bring a recent impressive result from DeepMind\cite{dingObjectbasedAttentionSpatiotemporal2020}, where the authors manage to surpass neuro-symbolic state-of-the-art proposals (a) on a task designed \textit{specifically} to focus on reasoning and expected to favour neuro-symbolic approaches\cite{yiCLEVRERCollisionEvents2019}, while (b) using less than 60\% of available labelled data, artificially inflating the dataset by masking part of the image and implementing self-supervised learning.


\end{document}